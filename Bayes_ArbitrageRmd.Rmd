---
title: "Bayesian Arbitrage"
author: "Ziren Wang, Hanxuan Lin"
date: "2022-11-25"
output:
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# AR(2) model

```{r}
library(ggplot2)

df <- read.csv('gold_price.csv')
Y <- data.frame(df$PD)
p = 2  # time dependence 
T1 = nrow(Y)
```

## regression matrix

```{r}
regression_matrix  <- function(data,p,constant){
    nrow <- as.numeric(dim(data)[1])
    nvar <- as.numeric(dim(data)[2])
    
    Y1 <- as.matrix(data, ncol = nvar)
    X <- embed(Y1, p+1)
    X <- X[,(nvar+1):ncol(X)]
    if(constant == TRUE){
        X <-cbind(rep(1,(nrow-p)),X)
    }
    Y = matrix(Y1[(p+1):nrow(Y1),])
    nvar2 = ncol(X)
    return = list(Y=Y, X=X, nvar2=nvar2, nrow=nrow) 
}
```

## companion matrix

```{r}
ar_companion_matrix <- function(beta){
    #check if beta is a matrix
    if (is.matrix(beta) == FALSE){
        stop('error: beta needs to be a matrix')
    }
    # dont include constant
    k = nrow(beta) - 1
    FF <- matrix(0, nrow = k, ncol = k)
    
    #insert identity matrix
    FF[2:k, 1:(k-1)] <- diag(1, nrow = k-1, ncol = k-1)
   
    temp <- t(beta[2:(k+1), 1:1])
    #state space companion form
    #Insert coeffcients along top row
    FF[1:1,1:k] <- temp
    return(FF)
}
```

## priors

```{r}
results = list()
results <- regression_matrix(Y, p, TRUE)

X <- results$X
Y <- results$Y
nrow <- results$nrow
nvar <- results$nvar

# Initialise Priors
B <- c(rep(0, nvar))
B0 <- as.matrix(B, nrow = 1, ncol = nvar)  # mean matrix
sigma0 <- diag(1,nvar)  # covariance matrix
T0 = 1 # prior degrees of freedom for the inv-gamma prior distribution
D0 = 0.1 # prior scale (theta0) for inv-gamma prior distribution

# initial value for variance
sigma2 = 1 
```


```{r}
reps = 15000
burn = 4000  #
horizon = 10  # 10-steps forward
out = matrix(0, nrow = reps, ncol = nvar + 1)
colnames(out) <- c('constant', 'beta1', 'beta2', 'sigma')
out1 <- matrix(0, nrow = reps, ncol = horizon)
```


## Gibbs Sampling

```{r}
gibbs_sampler <- function(X, Y, B0, sigma0, sigma2, theta0, D0, reps, out, out1){
  
  for(i in 1:reps){
    
    if (i %% 1000 == 0){
    print(sprintf("Iteration: %d", i))
    }
    
    # the mean of posterior parameters
    M = solve(solve(sigma0) + as.numeric(1/sigma2) * t(X) %*% X) %*%
        (solve(sigma0) %*% B0 + as.numeric(1/sigma2) * t(X) %*% Y)
    
    # the variance of posterior parameters
    V = solve(solve(sigma0) + as.numeric(1/sigma2) * t(X) %*% X)
    
    chck = -1
    
    while(chck < 0){   # check for stability
        
        # Draw of B from conditional posterior distribution
        # it is a trick by sampling from normal distribution
        B <- M + t(rnorm(p+1) %*% chol(V))
        #print(B) # the draw of alpha, beta1, beta2
        
        # Check : not stationary for 3 lags
        b = ar_companion_matrix(B)
        #print(b)
        ee <- max(sapply(eigen(b)$values, abs))
        #print(ee)
        if(ee <= 1){
            chck = 1
        }
        #print(chck)
    }
    
    # compute residuals
    resids <- Y - X %*% B
    T2 = T0 + T1  # DOF plus num of samples
    D1 = D0 + t(resids) %*% resids
    
    # keeps samples after burn period
    out[i,] <- t(matrix(c(t(B),sigma2)))
    
    
    #draw from Inverse Gamma
    z0 = rnorm(T2,1)
    z0z0 = t(z0) %*% z0
    sigma2 = D1/z0z0
    
    # keeps samples after burn period(store parameters)
    out[i,] <- t(matrix(c(t(B),sigma2)))
    
    # compute 60 trading days forecasts
    yhat = rep(0,horizon)
    end = as.numeric(length(Y))
    yhat[1:2] = Y[(end-1):end,]  # first 2 values for prediction
    cfactor = sqrt(sigma2) 
    X_mat = c(1,rep(0,p)) # [1,0,0] ~ [alpha, b1, b2]
    #print(X_mat)
    
    for(m in (p+1):horizon){  # in this example it is 3:10
      for(lag in 1:p){
        #create X matrix with p lags
        X_mat[(lag+1)] = yhat[m-lag]
        }
        # Use X matrix to forecast yhat
        yhat[m] = X_mat %*% B + rnorm(1) * cfactor
    }
    out1[i,] <- yhat # pred values
  }
  
  return = list(out,out1)
}
```

```{r}
# gibbs sampling all the parameters
results1 <- gibbs_sampler(X,Y,B0,sigma0,sigma2,T0,D0,reps,out,out1)
```

```{r}
# burn first 4000, so the results would be more stable if we start from a lousy assumption to reach the equilibrium
coef <- results1[[1]][(burn+1):reps, ]
forecasts <- results1[[2]][(burn+1):reps, ]
```

```{r}
const <- mean(coef[,1])
beta1 <- mean(coef[,2])
beta2 <- mean(coef[,3])
sigma <- mean(coef[,4])
```

## Posterior Plotting
```{r}
qplot(coef[,1], geom = "histogram", bins = 45, main = 'Distribution of Constant',
      colour="#FF9999")
```

```{r}
qplot(coef[,2], geom = "histogram", bins = 45,main = 'Distribution of Beta1',
      colour="#FF9999")
```

```{r}
qplot(coef[,3], geom = "histogram", bins = 45,main = 'Distribution of Beta2',
      colour="#FF9999")
```

```{r}
qplot(coef[,4], geom = "histogram", bins = 45,main = 'Distribution of Sigma',
      colour="#FF9999")
```

## Forecasting
```{r}
library(matrixStats)
library(reshape2)

# Quantiles for all data points, makes plotting easier
post_means <- colMeans(coef)
forecasts_m <- as.matrix(colMeans(forecasts))  # the mean prediction of 15000 reps
```

```{r}
# Creating error bands/credible intervals around our forecasts
error_bands <- colQuantiles(forecasts,prob = c(0.16,0.84))
Y_temp = cbind(Y,Y)
error_bands_updated <- rbind(Y_temp, error_bands[3:dim(error_bands)[1],])
all <- as.matrix(c(Y[1:(length(Y)-2)],forecasts_m))
forecasts.mat <- cbind.data.frame(error_bands_updated[,1], all, error_bands_updated[,2])
names(forecasts.mat) <- c('lower', 'mean', 'upper')
```

```{r}
# need to generate the forward 60 business days after 2022.8.8
library(timeDate)
holidays = holidayNYSE()
daysSeq = as.timeDate(seq(from = as.Date("2022-08-09"), to = as.Date("2022-11-01"), by = "day"))
fd_buis <- daysSeq[isBizday(daysSeq, holidays = holidays, wday = 1:5)]

#convert the dates into strings
df.dates = data.frame(date=fd_buis@Data)
df.dates2 <- read.csv('mydates.csv')
```

```{r}
prev_dates = as.data.frame(df$trade_dt)
colnames(prev_dates) <- c('date')
all_dates = rbind(prev_dates, df.dates2)
```

```{r}
prev_dates
```

```{r}
# create date vector for plotting
data.plot <- cbind.data.frame(all_dates$date, forecasts.mat)
colnames(data.plot) <- c('dates', 'lower', 'mean', 'upper')
data.plot$dates = as.Date(data.plot$dates)

# plot the prediction
data_subset <- data.plot[2397:2423,]
data_fore <- data.plot[2416:2423,]
ggplot(data_subset, aes(x = dates, y = mean, group = 1)) + geom_line(colour = 'blue', lwd = 0.5) + geom_ribbon(data = data_fore,
aes(x = dates, ymin = lower, ymax = upper, colour = "bands", alpha = 0.2)) +
  theme(axis.text.x = element_text(angle = 90))
```

# BSTS model
```{r}
library(zoo)
data <- read.csv.zoo("gold_price.csv",index.colum = "trade_dt")
short <- tail(data,n=500) # 500 data points for experiments
```

## Model Specifying
```{r}
library(bsts)
ss <- AddLocalLinearTrend(list(), short$PD)
ss <- AddAr(ss,short$PD,lags = 2)
ss <- AddSeasonal(ss, short$PD, nseasons = 52)
model <- bsts(PD ~ ., state.specification = ss, data =
                short, niter = 1000)
```

## Plotting
```{r}
plot(model)
plot(model, "components")
plot(model,"coefficients")
```

```{r}
ss <- AddLocalLinearTrend(list(), short$PD)
ss <- AddAr(ss,short$PD,lags = 2)
ss <- AddSeasonal(ss, short$PD, nseasons = 52)
model2 <- bsts(short$PD, state.specification = ss, niter = 1000)
pred1 <- predict(model2, horizon = 10)
plot(pred1, plot.original = 156)
```

```{r}
CompareBstsModels(list("pure time series" = model,
"with Predictors" = model2))
```



